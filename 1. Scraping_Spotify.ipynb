{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraction of Songs and Spotify Features Using Spotipy and the Spotify API\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This notebook delineates the initial data gathering process. A list of artists was gathered from Google with their most associated genres and put into a `csv` file named `singers.csv`. This file is then used to search Spotify using the Spotify API in order to extract the Artist's URI. Once the Artist's URI has been extracted, the top 10 songs of the artist (across albums) are extracted and the preview URI is stored in a dataframe. Using the track URI, the features of the song are extracted and stored in a dataframe. Finally, the music files themselves are downloaded as mp3 files in order to run custom feature extraction later on.\n",
    "\n",
    "Warning: Some artists do not have preview urls because of regional restrictions, account restrictions or the URI not being extractable. Therefore, the process does not always yield the same results. The Spotify account used in this scraping process has Norway as its default country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spotipy\n",
    "import pandas as pd\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "import time\n",
    "import random\n",
    "import requests\n",
    "import regex\n",
    "from string import punctuation\n",
    "client_id = \"6f8bb3e64c2944d586037b9907043601\"\n",
    "client_secret = \"81f5f44660364831be8d9118ccb51785\"\n",
    "client_credentials_manager = SpotifyClientCredentials(client_id=client_id, client_secret=client_secret)\n",
    "sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the `singers.csv` file which contains our list of singers and their most associated genres. This file will be used to populate the dataframe from which all of the other analysis will be conducted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "singers = pd.read_csv('singers.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Artist URI` is extracted using the following code. The `URI` is an identifier unique to Spotify using which all the relevant albums, tracks and other details of an artist can be gathered. The code creates appends a column with the `Artist URI` to the dataframe `singers` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(singers)):\n",
    "    artist = singers.loc[i,'Singers']\n",
    "    result = sp.search(artist)\n",
    "    singers.loc[i, 'URI'] = result['tracks']['items'][0]['artists'][0]['uri']\n",
    "    print(\"URI of\", result['tracks']['items'][0]['artists'][0]['name'], \"has been added to dataframe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code adds the `Track URIs` and `Preview URLs` to lists. The API is pinged using the `Artist API` and their tracks and previews are extracted and stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_uri = []\n",
    "track_uri = []\n",
    "track_preview = []\n",
    "for artist in singers['URI']:\n",
    "    results = sp.artist_top_tracks(artist)\n",
    "    for track in results['tracks'][:10]:\n",
    "        try:  \n",
    "            artist_uri.append(artist)\n",
    "            track_uri.append(track['uri'])\n",
    "            track_preview.append(track['preview_url'])\n",
    "        except:\n",
    "            next    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These extracted features are joined together in a dataframe. The dataframe is merged with the earlier `Singers` dataframe. The missing values are dropped because if the `Preview URL` is missing, custom feature extraction cannot be done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_df = pd.DataFrame()\n",
    "track_df['Artist'] = artist_uri\n",
    "track_df['TrackURI'] = track_uri\n",
    "track_df['Preview'] = track_preview\n",
    "total_df = pd.merge(singers, track_df, how = 'outer', left_on='URI', right_on = 'Artist')\n",
    "total_df2 = total_df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `Track URI`, spotify's API will be used to extract all the relevant features to be used in the Machine Learning algorithms employed later. These features are stored in a new dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(total_df2['TrackURI'])\n",
    "df.columns = ['TrackURI']\n",
    "\n",
    "for i in range(0,df.shape[0]):\n",
    "  try:\n",
    "    time.sleep(random.uniform(3, 6))\n",
    "    URI = df.TrackURI[i]\n",
    "    features = sp.audio_features(URI)\n",
    "    track = sp.track(URI)\n",
    "    df.loc[i, 'track'] = track['name']\n",
    "    df.loc[i,'acousticness'] = features[0]['acousticness']\n",
    "    df.loc[i,'instrumentalness'] = features[0]['instrumentalness']\n",
    "    df.loc[i,'energy'] = features[0]['energy']\n",
    "    df.loc[i,'speechiness'] = features[0]['speechiness']\n",
    "    df.loc[i,'liveness'] = features[0]['liveness']\n",
    "    df.loc[i,'loudness'] = features[0]['loudness']\n",
    "    df.loc[i,'danceability'] = features[0]['danceability']\n",
    "    df.loc[i,'tempo'] = features[0]['tempo']\n",
    "    df.loc[i,'valence'] = features[0]['valence']\n",
    "    uri=0\n",
    "  except:\n",
    "    next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After extraction of features, NA's are dropped, this feature dataframe is merged with the earlier dataframe containing all the relevant track details. This dataframe is then saved as `subsampled.csv` which is provided and can be used in further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df[-df['track'].isna()]\n",
    "new_df2 = pd.merge(total_df2, new_df, how = 'left', left_on = 'TrackURI', right_on = 'TrackURI')\n",
    "new_df2 = new_df2[-new_df2['track'].isna()]\n",
    "new_df2.to_csv('subsampled.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, there were only a few qawwali artists so we'll have to manually download the data for the genres which have fewer instances by looking up albums. The code below creates a `get_data` function which is used to extract the same features from playlists provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(playlist, genre):\n",
    "  playlist_link = playlist\n",
    "  playlist_URI = playlist_link.split(\"/\")[-1].split(\"?\")[0]\n",
    "  track_uris = [x[\"track\"][\"uri\"] for x in sp.playlist_tracks(playlist_URI)[\"items\"]]\n",
    "  df = pd.DataFrame(track_uris)\n",
    "  df.columns = ['TrackURI']\n",
    "  for i in range(df.shape[0]):\n",
    "    try:\n",
    "      URI = df.TrackURI[i]\n",
    "      track = sp.track(track_uris[i])\n",
    "      features = sp.audio_features(URI)\n",
    "      df.loc[i, 'Singers'] = track['artists'][0]['name']\n",
    "      df.loc[i, 'Genre'] = genre\n",
    "      df.loc[i, 'Artist'] = track['artists'][0]['uri']\n",
    "      df.loc[i, 'Preview'] = track['preview_url']\n",
    "      df.loc[i, 'track'] = track['name']\n",
    "      df.loc[i,'acousticness'] = features[0]['acousticness']\n",
    "      df.loc[i,'instrumentalness'] = features[0]['instrumentalness']\n",
    "      df.loc[i,'energy'] = features[0]['energy']\n",
    "      df.loc[i,'speechiness'] = features[0]['speechiness']\n",
    "      df.loc[i,'liveness'] = features[0]['liveness']\n",
    "      df.loc[i,'loudness'] = features[0]['loudness']\n",
    "      df.loc[i,'danceability'] = features[0]['danceability']\n",
    "      df.loc[i,'tempo'] = features[0]['tempo']\n",
    "      df.loc[i,'valence'] = features[0]['valence']\n",
    "    except:\n",
    "      next\n",
    "  \n",
    "  return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pieces of code below contain new playlists manually searched and appended to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qawwali = \"https://open.spotify.com/playlist/0USwGwasJVrHVN5Xkdhw0d?si=de90c13a7b4a4d4f\"\n",
    "qawwali2 = \"https://open.spotify.com/playlist/0CgbguP9exGwRVdRXLMsPS?si=c902a490d29e4277\"\n",
    "qawwali3 = \"https://open.spotify.com/playlist/0CgbguP9exGwRVdRXLMsPS?si=f25dd5cf963048e1\"\n",
    "ghazal = \"https://open.spotify.com/playlist/23aE9YFTUW11CcyoQhbGzT?si=79d1f449158d4a01\"\n",
    "ghazal2 = \"https://open.spotify.com/playlist/3C50t7049A6xf4w0rhfwgD?si=83083f7f5fc7460b\"\n",
    "edm = \"https://open.spotify.com/playlist/2NIe54HdwR5msTjrlHG1Lt?si=ff336b7898a24f98\"\n",
    "metal = \"https://open.spotify.com/playlist/27gN69ebwiJRtXEboL12Ih?si=838e862f19144616\"\n",
    "\n",
    "\n",
    "qawwali_df = get_data(qawwali, 'Qawwali') \n",
    "qawwal_df2 = get_data(qawwali2, 'Qawwali')\n",
    "qawwali_df3 = get_data(qawwali3, 'Qawwali') \n",
    "ghazal_df = get_data(ghazal, 'Ghazal')\n",
    "ghazal_df2 = get_data(ghazal2, 'Ghazal')\n",
    "edm_df = get_data(edm, 'EDM')\n",
    "metal_df = get_data(metal, 'Metal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qawwali_df = pd.concat([qawwali_df, qawwali_df2, qawwali_df3], ignore_index=True)\n",
    "ghazal_df = pd.concat([ghazal_df, ghazal_df2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qawwali_df.dropna(inplace = True)\n",
    "ghazal_df.dropna(inplace = True)\n",
    "edm_df.dropna(inplace = True)\n",
    "metal_df.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "album_data = pd.concat([qawwali_df, ghazal_df, edm_df, metal_df], ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the process is repeated to get a similar dataframe as the one saved to `subsampled.csv`, the two dataframes are concatenated. The newer augmented dataframe is once again saved as `subsampled.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsampled = pd.concat([subsampled, album_data], ignore_index = True)\n",
    "subsampled.drop_duplicates(inplace = True)\n",
    "subsampled['Genre'].value_counts()\n",
    "subsampled.to_csv('subsampled.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code uses the `Preview URLs` stored in subsampled to download all the songs that have been used in subsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(a)):\n",
    "    url = subsampled.loc[i, \"Preview\"]\n",
    "    genre = subsampled.loc[i, \"Genre\"]\n",
    "    track_name = subsampled.loc[i, \"track\"]\n",
    "    track_name = ' '.join(regex.findall('[A-Za-z0-9]+', track_name))\n",
    "      \n",
    "    mp3file = requests.get(url)\n",
    "    os.makedirs(f'./music/{genre}', exist_ok=True)\n",
    "    with open(f'./music/{genre}/{str(i).zfill(3)}_{track_name.strip(punctuation)}.mp3','wb') as output:\n",
    "          output.write(mp3file.content)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d6ab9c43d0ffc6a876efc8f7abb63dfedf6720c760e248878e2dbeb06a287133"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
